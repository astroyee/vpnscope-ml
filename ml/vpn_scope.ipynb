{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scikit-learn å·¥å…·\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# æ¨¡å‹\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ ¸å¿ƒé…ç½®\n",
    "FILE_PATH = 'data/processed/TimeBasedFeatures-Dataset-15s-VPN.arff' # è¯·ç¡®è®¤è·¯å¾„æ­£ç¡®\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5837d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(file_path):\n",
    "    # --- 1. åŠ è½½ ARFF ---\n",
    "    print(f\"ğŸ“‚ Loading data from: {file_path}\")\n",
    "    data, meta = arff.loadarff(file_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # è§£ç  byte å­—ç¬¦ä¸²\n",
    "    str_cols = df.select_dtypes([object]).columns\n",
    "    for col in str_cols:\n",
    "        df[col] = df[col].str.decode('utf-8')\n",
    "\n",
    "    # --- 2. æ ‡ç­¾å¤„ç† ---\n",
    "    target_col = df.columns[-1]\n",
    "    print(f\"   -> Target column identified: '{target_col}'\")\n",
    "    \n",
    "    # å®šä¹‰æ ‡ç­¾æ˜ å°„é€»è¾‘ (Non-VPN -> 0, VPN -> 1)\n",
    "    def map_label(label):\n",
    "        label_str = str(label).lower()\n",
    "        if 'non-vpn' in label_str: return 0\n",
    "        if 'vpn' in label_str or 'tor' in label_str: return 1\n",
    "        return 0\n",
    "\n",
    "    df['Binary_Label'] = df[target_col].apply(map_label)\n",
    "    \n",
    "    # æ‰“å°åˆ†å¸ƒ\n",
    "    y = df['Binary_Label']\n",
    "    print(f\"   -> Class Distribution: Normal(0)={sum(y==0)}, VPN(1)={sum(y==1)}\")\n",
    "\n",
    "    # --- 3. ç‰¹å¾æå– ---\n",
    "    cols_to_drop = [target_col, 'Binary_Label']\n",
    "    X = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # æ¸…æ´—æ•°å€¼ (NaN/Inf)\n",
    "    X = X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    X = X.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    return X, y, X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åŠ è½½æ•°æ®\n",
    "X_raw, y, feat_names = load_and_preprocess(FILE_PATH)\n",
    "\n",
    "# 2. åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† (7:3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# 3. å…¨å±€æ ‡å‡†åŒ– (è¿™å¯¹ MLP å’Œ Stacking è‡³å…³é‡è¦)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ä¿æŒ DataFrame æ ¼å¼ä»¥ä¾¿åç»­é€šè¿‡åˆ—åç´¢å¼• (å¯é€‰ï¼Œæ–¹ä¾¿è°ƒè¯•)\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=feat_names)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=feat_names)\n",
    "\n",
    "print(\"\\nâœ… Data Pipeline Ready.\")\n",
    "print(f\"   Training samples: {X_train.shape[0]}\")\n",
    "print(f\"   Testing samples:  {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5927962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. è®­ç»ƒåŸºå‡† RF ---\n",
    "print(\"ğŸš€ Training Baseline Random Forest...\")\n",
    "rf_baseline = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "rf_baseline.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_baseline.predict(X_test_scaled)\n",
    "\n",
    "print(f\"   -> Baseline Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"   -> Baseline F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "# --- 2. å¯è§†åŒ– ---\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: æ··æ·†çŸ©é˜µ\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Random Forest)')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "\n",
    "# Subplot 2: t-SNE é™ç»´å¯è§†åŒ– (é‡‡æ · 1000 ä¸ªç‚¹)\n",
    "print(\"ğŸ¨ Generating t-SNE plot...\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sample_idx = np.random.choice(len(X_train_scaled), min(1000, len(X_train_scaled)), replace=False)\n",
    "X_sample = X_train_scaled[sample_idx]\n",
    "y_sample = y_train.iloc[sample_idx]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=30)\n",
    "X_embedded = tsne.fit_transform(X_sample)\n",
    "\n",
    "scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_sample, cmap='coolwarm', alpha=0.6, s=20)\n",
    "plt.legend(handles=[mpatches.Patch(color='#6788ee', label='Normal (0)'), \n",
    "                    mpatches.Patch(color='#e46c5e', label='VPN (1)')])\n",
    "plt.title('t-SNE Visualization (Feature Space)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš”ï¸ Comparing Advanced Models...\")\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=N_JOBS),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE, n_jobs=N_JOBS),\n",
    "    \"MLP (Neural Net)\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "results = []\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # è®¡ç®— ROC\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # è®°å½•\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results.append({\"Model\": name, \"F1\": f1, \"AUC\": roc_auc})\n",
    "    print(f\"   -> {name}: F1={f1:.4f}, AUC={roc_auc:.4f}\")\n",
    "    \n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC={roc_auc:.3f})')\n",
    "\n",
    "# ç»˜å›¾\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# å±•ç¤ºæ¦œå•\n",
    "pd.DataFrame(results).sort_values(by=\"F1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0af8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ Tuning Random Forest Hyperparameters...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "grid = GridSearchCV(rf_base, param_grid, cv=3, scoring='f1', n_jobs=N_JOBS, verbose=1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "print(f\"\\nâœ… Best Params: {best_params}\")\n",
    "print(f\"   Best CV F1: {grid.best_score_:.4f}\")\n",
    "print(f\"   Test Set F1: {f1_score(y_test, best_rf.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e854df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš–ï¸ Final Stability Check (5-Fold Stratified CV)...\")\n",
    "\n",
    "# å®šä¹‰é€‰æ‰‹\n",
    "model_default = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "model_tuned = best_rf # ä½¿ç”¨ä¸Šé¢å¾®è°ƒå‡ºçš„æœ€ä½³æ¨¡å‹\n",
    "\n",
    "# å®šä¹‰è£åˆ¤ (å¿…é¡» Shuffle ä»¥æ‰“ç ´æ—¶é—´åºåˆ—ç›¸å…³æ€§)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# æ¯”èµ›\n",
    "scores_def = cross_val_score(model_default, X_raw, y, cv=cv, scoring='f1', n_jobs=N_JOBS) # æ³¨æ„ç”¨ X_raw\n",
    "scores_tun = cross_val_score(model_tuned, X_raw, y, cv=cv, scoring='f1', n_jobs=N_JOBS)\n",
    "\n",
    "# ç»“æœå¯è§†åŒ–\n",
    "res_df = pd.DataFrame({'Default RF': scores_def, 'Tuned RF': scores_tun})\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=res_df, palette=\"Set3\", width=0.5)\n",
    "sns.stripplot(data=res_df, color=\".25\", size=5)\n",
    "plt.title(f'Stability Analysis (Mean F1: Tuned={scores_tun.mean():.4f})')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§± Building Final Stacking Ensemble...\")\n",
    "\n",
    "# 1. åŸºå­¦ä¹ å™¨ (åˆ©ç”¨ä¹‹å‰çš„æœ€ä½³å‚æ•° + äº’è¡¥æ¨¡å‹)\n",
    "estimators = [\n",
    "    ('rf', best_rf), # å¾®è°ƒåçš„ RF\n",
    "    ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE, n_jobs=N_JOBS)),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "# 2. å…ƒå­¦ä¹ å™¨\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# 3. è®­ç»ƒ Stacking\n",
    "clf_stack = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5, n_jobs=N_JOBS)\n",
    "clf_stack.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. è¯„ä¼°\n",
    "y_pred_stack = clf_stack.predict(X_test_scaled)\n",
    "stack_f1 = f1_score(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"âœ… Final Stacking F1-Score: {stack_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ Optimizing Decision Threshold...\")\n",
    "\n",
    "# è·å–æ¦‚ç‡\n",
    "y_prob_stack = clf_stack.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# éå†é˜ˆå€¼å¯»æ‰¾æœ€ä½³ F1\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob_stack)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_idx]\n",
    "best_f1_val = f1_scores[best_idx]\n",
    "\n",
    "print(f\"   -> Default Threshold (0.50) F1: {stack_f1:.4f}\")\n",
    "print(f\"   -> Optimal Threshold ({best_thresh:.4f}) F1: {best_f1_val:.4f}\")\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(thresholds, f1_scores[:-1], label='F1 Score', color='navy')\n",
    "plt.axvline(best_thresh, color='red', linestyle='--', label=f'Best Threshold: {best_thresh:.2f}')\n",
    "plt.title('F1 Score vs Decision Threshold')\n",
    "plt.xlabel('Threshold'); plt.ylabel('F1 Score')\n",
    "plt.legend(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
